{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from data import Dataset\n",
    "from training import train_pythae_model\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "\n",
    "from metrics import NDCG_binary_at_k_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dotdict(dict):\n",
    "        \"\"\"dot.notation access to dictionary attributes\"\"\"\n",
    "        __getattr__ = dict.get\n",
    "        __setattr__ = dict.__setitem__\n",
    "        __delattr__ = dict.__delitem__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {}\n",
    "\n",
    "args = dotdict(args)\n",
    "args['data'] = 'gowalla' #'foursquare'\n",
    "\n",
    "args['model'] = 'MultiCIWAE' #SimCLR_reco_model, MultiVAE, BYOL_reco_model\n",
    "\n",
    "args['n_epoches'] = 100\n",
    "\n",
    "args['n_epoches_dec'] = 50\n",
    "\n",
    "args['lrdec'] = 1e-3\n",
    "\n",
    "args['lrenc'] = 1e-3\n",
    "\n",
    "args['train_batch_size'] = 1024\n",
    "\n",
    "args['val_batch_size'] = 200\n",
    "\n",
    "args['n_val_samples'] = 1\n",
    "\n",
    "args['annealing'] = True\n",
    "\n",
    "args.total_anneal_steps = 50\n",
    "\n",
    "args.anneal_cap = 1.\n",
    "\n",
    "args.print_info_ = 5\n",
    "\n",
    "args.metric = NDCG_binary_at_k_batch\n",
    "\n",
    "args.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "args.n_views = 2\n",
    "\n",
    "args.temperature = .07\n",
    "\n",
    "args.dropout_rate = 0.83\n",
    "\n",
    "args.criterion_dec = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "args.m = 0.995"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset(args)\n",
    "# pdb.set_trace()\n",
    "layers = [100, 600, dataset.n_items]\n",
    "args.z_dim = layers[0]\n",
    "args.l2_coeff = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1024, 21208])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(dataset.next_train_batch()).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from other_models import *\n",
    "from pythae.models import VAMPConfig, VAEConfig, VAE_LinNF_Config, VAE_IAF_Config\n",
    "from pythae.models.nn import BaseEncoder, BaseDecoder\n",
    "from pythae.models.base.base_utils import ModelOutput\n",
    "from models import make_linear_network\n",
    "\n",
    "\n",
    "class Encoder(BaseEncoder):\n",
    "    def __init__(self, dims):\n",
    "        BaseDecoder.__init__(self)\n",
    "        self.layers = make_linear_network(\n",
    "            dims,\n",
    "            encoder=True\n",
    "        )\n",
    "        self.dims = dims\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layers(x)\n",
    "        return ModelOutput(\n",
    "            embedding=out[:, :self.dims[-1]],\n",
    "            log_covariance=out[:, self.dims[-1]:]\n",
    "            )\n",
    "    \n",
    "class Decoder(BaseDecoder):\n",
    "    def __init__(self, dims):\n",
    "        BaseDecoder.__init__(self)\n",
    "        self.layers = make_linear_network(\n",
    "            dims,\n",
    "            encoder=False\n",
    "        )\n",
    "        self.dims = dims\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layers(x)\n",
    "        return ModelOutput(\n",
    "            reconstruction=out[:self.dims[-1]]\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1109.2017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/clement/Documents/recommender_systems_experiments/src/metrics.py:32: RuntimeWarning: invalid value encountered in divide\n",
      "  a = DCG / IDCG\n",
      "  0%|          | 0/100 [00:11<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best NDCG: 0.08965297658064632\n",
      "Current NDCG: 0.08965297658064632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "Error",
     "evalue": "You must call wandb.init() before wandb.log()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mError\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 76\u001b[0m\n\u001b[1;32m     65\u001b[0m     config \u001b[39m=\u001b[39m CIWAEConfig(\n\u001b[1;32m     66\u001b[0m         latent_dim\u001b[39m=\u001b[39margs\u001b[39m.\u001b[39mz_dim,\n\u001b[1;32m     67\u001b[0m         input_dim\u001b[39m=\u001b[39m(\u001b[39m21208\u001b[39m,),\n\u001b[1;32m     68\u001b[0m         number_samples\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m\n\u001b[1;32m     69\u001b[0m     )\n\u001b[1;32m     71\u001b[0m     model \u001b[39m=\u001b[39m MultiCIWAE(model_config\u001b[39m=\u001b[39mconfig,\n\u001b[1;32m     72\u001b[0m         encoder\u001b[39m=\u001b[39mEncoder(dims\u001b[39m=\u001b[39mlayers[::\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]),\n\u001b[1;32m     73\u001b[0m         decoder\u001b[39m=\u001b[39mDecoder(dims\u001b[39m=\u001b[39mlayers)\n\u001b[1;32m     74\u001b[0m     )\u001b[39m.\u001b[39mto(args\u001b[39m.\u001b[39mdevice)\n\u001b[0;32m---> 76\u001b[0m metric_values \u001b[39m=\u001b[39m train_pythae_model(model, dataset, args)\n",
      "File \u001b[0;32m~/Documents/recommender_systems_experiments/src/training.py:500\u001b[0m, in \u001b[0;36mtrain_pythae_model\u001b[0;34m(model, dataset, args)\u001b[0m\n\u001b[1;32m    497\u001b[0m             \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mCurrent NDCG:\u001b[39m\u001b[39m'\u001b[39m, current_metric)\n\u001b[1;32m    499\u001b[0m         \u001b[39mif\u001b[39;00m wandb_is_available():\n\u001b[0;32m--> 500\u001b[0m             wandb\u001b[39m.\u001b[39;49mlog(\n\u001b[1;32m    501\u001b[0m                 {\n\u001b[1;32m    502\u001b[0m                     \u001b[39m\"\u001b[39;49m\u001b[39mtrain/loss\u001b[39;49m\u001b[39m\"\u001b[39;49m: loss,\n\u001b[1;32m    503\u001b[0m                     \u001b[39m\"\u001b[39;49m\u001b[39mtrain/elbo\u001b[39;49m\u001b[39m\"\u001b[39;49m: elbo,\n\u001b[1;32m    504\u001b[0m                     \u001b[39m\"\u001b[39;49m\u001b[39meval/NDCG\u001b[39;49m\u001b[39m\"\u001b[39;49m: current_metric,\n\u001b[1;32m    505\u001b[0m                     \u001b[39m\"\u001b[39;49m\u001b[39meval/best_NDCG\u001b[39;49m\u001b[39m\"\u001b[39;49m: best_metric\n\u001b[1;32m    506\u001b[0m                 }\n\u001b[1;32m    507\u001b[0m             )\n\u001b[1;32m    509\u001b[0m path \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m../models/\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    512\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(path):\n",
      "File \u001b[0;32m~/anaconda3/envs/recomenders/lib/python3.8/site-packages/wandb/sdk/lib/preinit.py:36\u001b[0m, in \u001b[0;36mPreInitCallable.<locals>.preinit_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpreinit_wrapper\u001b[39m(\u001b[39m*\u001b[39margs: Any, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[0;32m---> 36\u001b[0m     \u001b[39mraise\u001b[39;00m wandb\u001b[39m.\u001b[39mError(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mYou must call wandb.init() before \u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m()\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mError\u001b[0m: You must call wandb.init() before wandb.log()"
     ]
    }
   ],
   "source": [
    "if args.model == \"MultiVAE\":\n",
    "    from other_models import MultiVAEPythae\n",
    "    from pythae.models import VAEConfig\n",
    "\n",
    "    config = VAEConfig(\n",
    "        latent_dim=args.z_dim,\n",
    "        input_dim=(26150,)\n",
    "    )\n",
    "\n",
    "    model = MultiVAEPythae(\n",
    "        model_config=config,\n",
    "        encoder=Encoder(dims=layers[::-1]),\n",
    "        decoder=Decoder(dims=layers)\n",
    "    ).to(args.device)\n",
    "\n",
    "elif args.model == \"MultiVAMP\":\n",
    "    from other_models import MultiVAMP\n",
    "    from pythae.models import VAMPConfig\n",
    "\n",
    "    config = VAMPConfig(\n",
    "        latent_dim=args.z_dim,\n",
    "        input_dim=(26150,),\n",
    "        n_components=500\n",
    "    )\n",
    "\n",
    "    model = MultiVAMP(model_config=config,\n",
    "        encoder=Encoder(dims=layers[::-1]),\n",
    "        decoder=Decoder(dims=layers)\n",
    "    ).to(args.device)\n",
    "\n",
    "elif args.model == \"MultiVAELinNF\":\n",
    "    from other_models import MultiVAELinNF\n",
    "    from pythae.models import VAE_LinNF_Config\n",
    "\n",
    "    config = VAE_LinNF_Config(\n",
    "        latent_dim=args.z_dim,\n",
    "        input_dim=(26150,),\n",
    "        flows=['Planar', 'Radial', 'Planar', 'Radial', 'Planar']\n",
    "    )\n",
    "\n",
    "    model = MultiVAELinNF(model_config=config,\n",
    "        encoder=Encoder(dims=layers[::-1]),\n",
    "        decoder=Decoder(dims=layers)\n",
    "    ).to(args.device)\n",
    "\n",
    "elif args.model == \"MultiVAEIAF\":\n",
    "    from other_models import MultiVAEIAF\n",
    "    from pythae.models import VAE_IAF_Config\n",
    "\n",
    "    config = VAE_IAF_Config(\n",
    "        latent_dim=args.z_dim,\n",
    "        input_dim=(26150,),\n",
    "        n_made_blocks=3\n",
    "    )\n",
    "\n",
    "    model = MultiVAEIAF(model_config=config,\n",
    "        encoder=Encoder(dims=layers[::-1]),\n",
    "        decoder=Decoder(dims=layers)\n",
    "    ).to(args.device)\n",
    "\n",
    "elif args.model == \"MultiCIWAE\":\n",
    "    from other_models import MultiCIWAE\n",
    "    from pythae.models import CIWAEConfig\n",
    "\n",
    "    config = CIWAEConfig(\n",
    "        latent_dim=args.z_dim,\n",
    "        input_dim=(21208,),\n",
    "        number_samples=5,\n",
    "        beta=0.5\n",
    "    )\n",
    "\n",
    "    model = MultiCIWAE(model_config=config,\n",
    "        encoder=Encoder(dims=layers[::-1]),\n",
    "        decoder=Decoder(dims=layers)\n",
    "    ).to(args.device)\n",
    "\n",
    "metric_values = train_pythae_model(model, dataset, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pythae.models import AutoModel\n",
    "\n",
    "model = AutoModel.load_from_folder(\"/home/clement/Documents/recommender_systems_experiments/models/best_model_MultiVAE_data_gowalla_K_None_N_None_learnreverse_False_anneal_False_lrdec_0.001_lrenc_None_learntransitions_False_initstepsize_0.005\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CIWAEConfig(name='CIWAEConfig', input_dim=(26150,), latent_dim=100, uses_default_encoder=False, uses_default_decoder=False, reconstruction_loss='mse', number_samples=5, beta=0.5)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.tes = 1.\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VAE(\n",
       "  (decoder): Decoder(\n",
       "    (layers): Sequential(\n",
       "      (0): Linear(in_features=200, out_features=600, bias=True)\n",
       "      (1): Tanh()\n",
       "      (2): Linear(in_features=600, out_features=21208, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (encoder): Encoder(\n",
       "    (layers): Sequential(\n",
       "      (0): Linear(in_features=21208, out_features=600, bias=True)\n",
       "      (1): BatchNorm1d(600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): Tanh()\n",
       "      (3): Linear(in_features=600, out_features=400, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "PytorchStreamReader failed locating file data.pkl: file not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[81], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m torch\u001b[39m.\u001b[39;49mload(\u001b[39m'\u001b[39;49m\u001b[39m../models/best_model_MultiVAELinNF_data_gowalla_K_None_N_None_learnreverse_False_anneal_False_lrdec_0.001_lrenc_None_learntransitions_False_initstepsize_0.005.pt\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m~/anaconda3/envs/recomenders/lib/python3.8/site-packages/torch/serialization.py:789\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[1;32m    787\u001b[0m             \u001b[39mexcept\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    788\u001b[0m                 \u001b[39mraise\u001b[39;00m pickle\u001b[39m.\u001b[39mUnpicklingError(UNSAFE_MESSAGE \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(e)) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m--> 789\u001b[0m         \u001b[39mreturn\u001b[39;00m _load(opened_zipfile, map_location, pickle_module, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mpickle_load_args)\n\u001b[1;32m    790\u001b[0m \u001b[39mif\u001b[39;00m weights_only:\n\u001b[1;32m    791\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/recomenders/lib/python3.8/site-packages/torch/serialization.py:1127\u001b[0m, in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1124\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mfind_class(mod_name, name)\n\u001b[1;32m   1126\u001b[0m \u001b[39m# Load the data (which may in turn use `persistent_load` to load tensors)\u001b[39;00m\n\u001b[0;32m-> 1127\u001b[0m data_file \u001b[39m=\u001b[39m io\u001b[39m.\u001b[39mBytesIO(zip_file\u001b[39m.\u001b[39;49mget_record(pickle_file))\n\u001b[1;32m   1129\u001b[0m unpickler \u001b[39m=\u001b[39m UnpicklerWrapper(data_file, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpickle_load_args)\n\u001b[1;32m   1130\u001b[0m unpickler\u001b[39m.\u001b[39mpersistent_load \u001b[39m=\u001b[39m persistent_load\n",
      "\u001b[0;31mRuntimeError\u001b[0m: PytorchStreamReader failed locating file data.pkl: file not found"
     ]
    }
   ],
   "source": [
    "torch.load('../models/best_model_MultiVAELinNF_data_gowalla_K_None_N_None_learnreverse_False_anneal_False_lrdec_0.001_lrenc_None_learntransitions_False_initstepsize_0.005.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recomenders",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31445e1c91ca14b00113211911eb8289a62146068036db2ba0d54800a345898a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
